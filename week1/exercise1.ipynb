{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Topics covered:\n",
    "\n",
    "- Overfitting and Underfitting:\n",
    "    - underfitting: a model that is too simple\n",
    "    - overfitting: a model that is not a good predictor\n",
    "- DummyRegressor\n",
    "- Linear Regression (Least Squares)\n",
    "- Polynomial Features \n",
    "- Regression Metrics (how good is your model?)\n",
    "    - R2 (R square) error: more common\n",
    "    - Mean Absolute error\n",
    "    - Mean Squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's read price of stock over time\n",
    "def getXAndY():\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv('stock.txt')\n",
    "    \n",
    "    # we need to do a reshape of the data because train_test_split expects a [[]] and the X is just one column []\n",
    "    return(df['time'].values.reshape(-1,1),df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(x,y)= getXAndY()   \n",
    "plt.plot(x,y,'ro')\n",
    "plt.ylabel('price')\n",
    "plt.xlabel('time/date')\n",
    "plt.title('Stock price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotResults(Xtr, Xtst, ytr, ytst, Xplot, y_plot, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    tr, = plt.plot(Xtr,ytr,'ro')\n",
    "    tst, = plt.plot(Xtst,ytst,'go')\n",
    "    plt.plot(Xplot,y_plot)\n",
    "    plt.legend([tr, tst], ['Train', 'Test'])\n",
    "    plt.ylabel('price')\n",
    "    plt.xlabel('time/date')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's make a model that always predict the mean: use DummyRegressor\n",
    "# r2_score (r-squared): it's a linear regression scoring function with a best score = or close to 1. \n",
    "def question1():\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    from sklearn.dummy import DummyRegressor\n",
    "    \n",
    "    (X,y)= getXAndY()\n",
    "    \n",
    "    # train_test_split with the default option assigns 75% of the points \n",
    "    # to train and 25% to test    \n",
    "    # use random_state = 0 (or any number) to make sure your results are repeatable\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
    "    \n",
    "    # returns the mean\n",
    "    dummyReg = DummyRegressor(strategy='mean').fit(X_train, y_train)\n",
    "    \n",
    "    # calculate our predicted values for train and test\n",
    "    y_pred_train = dummyReg.predict(X_train)\n",
    "    y_pred_test = dummyReg.predict(X_test)\n",
    "    \n",
    "    plotResults(X_train, X_test, y_train, y_test, X_train, y_pred_train,'Dummy Regressor')\n",
    "    \n",
    "    #compare the predicted values with the real ones\n",
    "    q1 = r2_score(y_train, y_pred_train)\n",
    "    q2 = r2_score(y_test, y_pred_test)\n",
    "    return (q1,q2)\n",
    "\n",
    "question1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a linear regression (default options) with a polynomial of degree = 1 ( a line)\n",
    "# print the weights (coefficients)\n",
    "def question2():\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "    \n",
    "    (X,y)= getXAndY()\n",
    "    \n",
    "    #complete:\n",
    "    \n",
    "    return \"r2_score for train and test\"\n",
    "\n",
    "question2()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a regression for a polynomial of degree 2 (y = ax^2 + bx + c)\n",
    "# PolynomialFeatures turns the data into a polynomial form\n",
    "# e.g. if we want to turn the data into a polynomial of degree 2:\n",
    "# and we have one feature x0, it will convert it to: x0, x0^2\n",
    "# for two features x1, x2, the data will convert to:  x0, x1, x0^2, x0*x1, x1^2\n",
    "def question3():\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    \n",
    "    (X,y)= getXAndY()\n",
    "    X_poly = PolynomialFeatures(degree=2,include_bias=False).fit_transform(X)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y, random_state=0)\n",
    "    \n",
    "    linreg = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred_train = linreg.predict(X_train)\n",
    "    y_pred_test = linreg.predict(X_test)\n",
    "    y_plot = linreg.predict(X_poly)\n",
    "    \n",
    "    # plot the original points train and test\n",
    "    X_train_orig, X_test_orig, y_train_orig, y_test_orig = train_test_split(X, y, random_state=0)\n",
    "    plotResults(X_train_orig, X_test_orig, y_train_orig, y_test_orig, X, y_plot,'Polynomial deg 2')\n",
    "    \n",
    "    print(linreg.intercept_, linreg.coef_)\n",
    "    q1 = r2_score(y_train, y_pred_train)\n",
    "    q2 = r2_score(y_test, y_pred_test)\n",
    "    return (q1,q2)\n",
    "\n",
    "question3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a linear regression for a polynomial of grade 10\n",
    "# return r2 scores for the training and testing set\n",
    "# change the degree between 3 and 10 what do you see?\n",
    "def question4():\n",
    "    \n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    \n",
    "    (X,y)= getXAndY()\n",
    "    \n",
    "    deg = 10\n",
    "    #complete:\n",
    "    \n",
    "    return \"r2_score for train and test\"\n",
    "\n",
    "\n",
    "question4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do a for loop from degree 2 through 9 for the data\n",
    "# capture the r2 scores for the test and training sets for each iteration\n",
    "# return the degree at which you think it's not overfitting or underfitting (high values for r2 scores\n",
    "# for both train and test sets)\n",
    "# extra credit: plot the r2 scores, in the x axis the training set r2, \n",
    "# in the y axis the r2 results for the test set, and label each of the points\n",
    "\n",
    "def question5():\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics.regression import r2_score\n",
    "    \n",
    "    (X,y)= getXAndY()\n",
    "    \n",
    "    return \"degree of the polynomial that does not overfit or underfit\" \n",
    "\n",
    "question5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
