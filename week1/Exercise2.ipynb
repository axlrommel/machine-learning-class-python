{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the crime dataset found here\n",
    "https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized\n",
    "\n",
    "\n",
    "below are the columns from the dataset:\n",
    "\n",
    "predictive_columns = ['population' 'householdsize' 'racepctblack' 'racePctWhite' 'racePctAsian'\n",
    " 'racePctHisp' 'agePct12t21' 'agePct12t29' 'agePct16t24' 'agePct65up'\n",
    " 'numbUrban' 'pctUrban' 'medIncome' 'pctWWage' 'pctWFarmSelf' 'pctWInvInc'\n",
    " 'pctWSocSec' 'pctWPubAsst' 'pctWRetire' 'medFamInc' 'perCapInc'\n",
    " 'whitePerCap' 'blackPerCap' 'indianPerCap' 'AsianPerCap' 'OtherPerCap'\n",
    " 'HispPerCap' 'NumUnderPov' 'PctPopUnderPov' 'PctLess9thGrade'\n",
    " 'PctNotHSGrad' 'PctBSorMore' 'PctUnemployed' 'PctEmploy' 'PctEmplManu'\n",
    " 'PctEmplProfServ' 'PctOccupManu' 'PctOccupMgmtProf' 'MalePctDivorce'\n",
    " 'MalePctNevMarr' 'FemalePctDiv' 'TotalPctDiv' 'PersPerFam' 'PctFam2Par'\n",
    " 'PctKids2Par' 'PctYoungKids2Par' 'PctTeen2Par' 'PctWorkMomYoungKids'\n",
    " 'PctWorkMom' 'NumKidsBornNeverMar' 'PctKidsBornNeverMar' 'NumImmig'\n",
    " 'PctImmigRecent' 'PctImmigRec5' 'PctImmigRec8' 'PctImmigRec10'\n",
    " 'PctRecentImmig' 'PctRecImmig5' 'PctRecImmig8' 'PctRecImmig10'\n",
    " 'PctSpeakEnglOnly' 'PctNotSpeakEnglWell' 'PctLargHouseFam'\n",
    " 'PctLargHouseOccup' 'PersPerOccupHous' 'PersPerOwnOccHous'\n",
    " 'PersPerRentOccHous' 'PctPersOwnOccup' 'PctPersDenseHous' 'PctHousLess3BR'\n",
    " 'MedNumBR' 'HousVacant' 'PctHousOccup' 'PctHousOwnOcc' 'PctVacantBoarded'\n",
    " 'PctVacMore6Mos' 'MedYrHousBuilt' 'PctHousNoPhone' 'PctWOFullPlumb'\n",
    " 'OwnOccLowQuart' 'OwnOccMedVal' 'OwnOccHiQuart' 'OwnOccQrange' 'RentLowQ'\n",
    " 'RentMedian' 'RentHighQ' 'RentQrange' 'MedRent' 'MedRentPctHousInc'\n",
    " 'MedOwnCostPctInc' 'MedOwnCostPctIncNoMtg' 'NumInShelters' 'NumStreet'\n",
    " 'PctForeignBorn' 'PctBornSameState' 'PctSameHouse85' 'PctSameCity85'\n",
    " 'PctSameState85' 'LemasSwornFT' 'LemasSwFTPerPop' 'LemasSwFTFieldOps'\n",
    " 'LemasSwFTFieldPerPop' 'LemasTotalReq' 'LemasTotReqPerPop'\n",
    " 'PolicReqPerOffic' 'PolicPerPop' 'RacialMatchCommPol' 'PctPolicWhite'\n",
    " 'PctPolicBlack' 'PctPolicHisp' 'PctPolicAsian' 'PctPolicMinor'\n",
    " 'OfficAssgnDrugUnits' 'NumKindsDrugsSeiz' 'PolicAveOTWorked' 'LandArea'\n",
    " 'PopDens' 'PctUsePubTrans' 'PolicCars' 'PolicOperBudg'\n",
    " 'LemasPctPolicOnPatr' 'LemasGangUnitDeploy' 'LemasPctOfficDrugUn'\n",
    " 'PolicBudgPerPop']\n",
    " \n",
    " \n",
    " target_columns:['murders' 'murdPerPop' 'rapes' 'rapesPerPop' 'robberies'\n",
    " 'robbbPerPop' 'assaults' 'assaultPerPop' 'burglaries' 'burglPerPop'\n",
    " 'larcenies' 'larcPerPop' 'autoTheft' 'autoTheftPerPop' 'arsons'\n",
    " 'arsonsPerPop' 'ViolentCrimesPerPop' 'nonViolPerPop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crime_dataset():\n",
    "    import pandas as pd\n",
    "    # Communities and Crime dataset for regression\n",
    "    # source:\n",
    "    # https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime+Unnormalized\n",
    "\n",
    "    df = pd.read_table('CommViolPredUnnormalizedData.txt', sep=',', na_values='?')\n",
    "    \n",
    "    # drop columns for city, state, etc. plus rows with values = na\n",
    "    crime = df.drop(df.columns[[0,1,2,3,4]],axis=1).dropna()\n",
    "    \n",
    "    # n columns based on the index\n",
    "    X_crime = crime.iloc[:,range(0,10)]\n",
    "    \n",
    "    # all predictive columns\n",
    "#     X_crime = crime.iloc[:,range(0,124)]\n",
    "\n",
    "    # select columns from a list\n",
    "#     X_crime = crime[['householdsize','racepctblack','racePctWhite','racePctAsian','racePctHisp']]\n",
    "    \n",
    "    # select just one column, will need to do a reshape\n",
    "#     X_crime = crime['perCapInc'].values.reshape(-1,1)\n",
    "    \n",
    "    # select any one column from the target columns\n",
    "    y_crime = crime['murdPerPop']\n",
    "\n",
    "    return (X_crime,y_crime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
      "9       103590           2.62         23.14         67.60          0.92   \n",
      "13       57140           2.74         53.52         45.65          0.49   \n",
      "17      180038           2.62          1.30         74.02         14.14   \n",
      "19      261721           2.60          8.41         82.64          3.92   \n",
      "21     7322564           2.60         28.71         52.26          7.00   \n",
      "\n",
      "    racePctHisp  agePct12t21  agePct12t29  agePct16t24  agePct65up  \n",
      "9         16.35        19.88        34.55        21.62       13.12  \n",
      "13         0.43        16.51        28.17        14.68       13.38  \n",
      "17        20.96        12.04        26.68        12.37       11.54  \n",
      "19         8.91        14.18        32.78        15.14        4.58  \n",
      "21        24.36        13.06        27.46        13.09       11.62  \n",
      "9     26.88\n",
      "13    27.26\n",
      "17     5.02\n",
      "19     2.39\n",
      "21    26.59\n",
      "Name: murdPerPop, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def printDataSet():\n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    print(X_crime.head())\n",
    "    print(y_crime.head())\n",
    "#     print(X_crime.columns.values)\n",
    "    \n",
    "printDataSet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59690236423467447, 0.67949819476183415)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform linear regression\n",
    "def ex1():\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action=\"ignore\", module=\"scipy\", message=\"^internal gelsd\")\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                   random_state = 0)\n",
    "    linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    return (linreg.score(X_train, y_train),linreg.score(X_test, y_test))\n",
    "\n",
    "ex1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78061368287329047, -0.055156513114217542)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perform polynomial regression of degree 2\n",
    "def ex1a():\n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_poly = PolynomialFeatures(degree=2,include_bias=False).fit_transform(X_crime)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_crime,\n",
    "                                                   random_state = 0)\n",
    "    linreg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    return (linreg.score(X_train, y_train),linreg.score(X_test, y_test))\n",
    "\n",
    "ex1a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7577837996817649, 0.42712193149261213)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to avoid the problems of overfitting polynomial regression of higher degrees, we put a penalty on the\n",
    "# coefficients that are large.\n",
    "# We use ridge regression which is a type of regularized linear regression that uses an alpha parameter \n",
    "# to penalizes for large coefs theta (to avoid overfitting):\n",
    "# As the magnitudes of the xi parameters increases (the higher the polunomial degree), the penalty increases as well \n",
    "def ex2():\n",
    "    \n",
    "    import numpy as np\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_poly = PolynomialFeatures(degree=2,include_bias=False).fit_transform(X_crime)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_crime,\n",
    "                                                   random_state = 0)\n",
    "    linridge = Ridge(alpha=20.0).fit(X_train, y_train)\n",
    "\n",
    "    return (linridge.score(X_train, y_train),linridge.score(X_test, y_test))\n",
    "\n",
    "ex2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.56772731184584013, 0.65054477060117732)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# when features vary wildly, e.g when calculating the price of the house: the square footage is in the thousands\n",
    "# and number of bedrooms is in the single digits, it's best to normalize the data to values \n",
    "# between 0 and 1 or -1 and 1, you use MinMaxScaler on most occasions - make sure there are no outliers\n",
    "def ex2a():\n",
    "    \n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.linear_model import Ridge\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_poly = PolynomialFeatures(degree=2,include_bias=False).fit_transform(X_crime)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_crime,\n",
    "                                                   random_state = 0)\n",
    "    # both training set and testing set need to be scaled\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    linridge = Ridge(alpha=20.0).fit(X_train_scaled, y_train)\n",
    "\n",
    "    return (linridge.score(X_train_scaled, y_train),linridge.score(X_test_scaled, y_test))\n",
    "\n",
    "ex2a()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.00\n",
      "r-squared training: 1.00, r-squared test: -1485.23\n",
      "Alpha = 1.00\n",
      "r-squared training: 0.68, r-squared test: 0.65\n",
      "Alpha = 10.00\n",
      "r-squared training: 0.62, r-squared test: 0.67\n",
      "Alpha = 20.00\n",
      "r-squared training: 0.60, r-squared test: 0.67\n",
      "Alpha = 50.00\n",
      "r-squared training: 0.58, r-squared test: 0.65\n",
      "Alpha = 100.00\n",
      "r-squared training: 0.55, r-squared test: 0.63\n",
      "Alpha = 1000.00\n",
      "r-squared training: 0.27, r-squared test: 0.30\n"
     ]
    }
   ],
   "source": [
    "# use min max scaler and ridge regressor with alpha values in [0, 1, 10, 20, 50, 100, 1000] with a polynomial\n",
    "# of degree 3\n",
    "# find the best alpha\n",
    "def ex3():\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(action=\"ignore\", module=\"scipy\")\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import Ridge\n",
    "    import numpy as np\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_poly = PolynomialFeatures(degree=3,include_bias=False).fit_transform(X_crime)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_crime,\n",
    "                                                       random_state = 0)\n",
    "\n",
    "    # both training set and testing set need to be scaled\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    for this_alpha in [0, 1, 10, 20, 50, 100, 1000]:\n",
    "        linridge = Ridge(alpha = this_alpha).fit(X_train_scaled, y_train)\n",
    "        r2_train = linridge.score(X_train_scaled, y_train)\n",
    "        r2_test = linridge.score(X_test_scaled, y_test)\n",
    "        print('Alpha = {:.2f}\\nr-squared training: {:.2f}, r-squared test: {:.2f}'\n",
    "             .format(this_alpha, r2_train, r2_test))\n",
    "\n",
    "ex3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0.10\n",
      "r-squared training: 0.63, r-squared test: 0.69\n",
      "Alpha = 0.50\n",
      "r-squared training: 0.53, r-squared test: 0.62\n",
      "Alpha = 1.00\n",
      "r-squared training: 0.43, r-squared test: 0.52\n",
      "Alpha = 2.00\n",
      "r-squared training: 0.16, r-squared test: 0.19\n",
      "Alpha = 3.00\n",
      "r-squared training: 0.00, r-squared test: -0.00\n",
      "Alpha = 5.00\n",
      "r-squared training: 0.00, r-squared test: -0.00\n",
      "Alpha = 10.00\n",
      "r-squared training: 0.00, r-squared test: -0.00\n",
      "Alpha = 20.00\n",
      "r-squared training: 0.00, r-squared test: -0.00\n",
      "Alpha = 50.00\n",
      "r-squared training: 0.00, r-squared test: -0.00\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression\n",
    "# another way of doing regularization is using the Lasso Regression, which also penalizes the coeficients\n",
    "# when doing the regression\n",
    "# Many small/medium sized effects: use Ridge\n",
    "# Only a few variables with medium/large effects: use Lasso\n",
    "# do a lasso regression for alpha in [0.1, 0.5, 1, 2, 3, 5, 10, 20, 50] and max_iter = 10000 and polynomial\n",
    "# of degree 4\n",
    "def ex4():\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import Lasso\n",
    "    import numpy as np\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_poly = PolynomialFeatures(degree=4,include_bias=False).fit_transform(X_crime)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_poly, y_crime,\n",
    "                                                       random_state = 0)\n",
    "\n",
    "    # both training set and testing set need to be scaled\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    for alpha in [0.1, 0.5, 1, 2, 3, 5, 10, 20, 50]:\n",
    "        linlasso = Lasso(alpha, max_iter = 10000).fit(X_train_scaled, y_train)\n",
    "        r2_train = linlasso.score(X_train_scaled, y_train)\n",
    "        r2_test = linlasso.score(X_test_scaled, y_test)\n",
    "        print('Alpha = {:.2f}\\nr-squared training: {:.2f}, r-squared test: {:.2f}'\n",
    "             .format(alpha, r2_train, r2_test))\n",
    "\n",
    "ex4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48715114223 0.562719985433\n"
     ]
    }
   ],
   "source": [
    "# Support Vector Machines transform of the data before finding a match \n",
    "def ex5():\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.svm import SVR\n",
    "    import numpy as np\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                       random_state = 0)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = SVR(C=10, epsilon=0.2).fit(X_train_scaled, y_train)\n",
    "    r2_train = clf.score(X_train_scaled, y_train)\n",
    "    r2_test = clf.score(X_test_scaled, y_test)\n",
    "    print(r2_train,r2_test)\n",
    "\n",
    "ex5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100.0}\n",
      "0.561732591767 0.639787265159\n"
     ]
    }
   ],
   "source": [
    "# Use GridSearchCV to run SVR with different parameters \n",
    "def ex6():\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    from sklearn.svm import SVR\n",
    "    import numpy as np\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    (X_crime,y_crime) = get_crime_dataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_crime, y_crime,\n",
    "                                                       random_state = 0)\n",
    "\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3]})\n",
    "    \n",
    "    clf = svr.fit(X_train_scaled, y_train)\n",
    "    print(clf.best_params_)\n",
    "    r2_train = clf.score(X_train_scaled, y_train)\n",
    "    r2_test = clf.score(X_test_scaled, y_test)\n",
    "    print(r2_train,r2_test)\n",
    "\n",
    "ex6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
